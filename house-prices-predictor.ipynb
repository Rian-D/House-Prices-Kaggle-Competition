{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10211,"databundleVersionId":111096,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-21T17:32:03.014044Z","iopub.execute_input":"2025-06-21T17:32:03.014412Z","iopub.status.idle":"2025-06-21T17:32:03.026455Z","shell.execute_reply.started":"2025-06-21T17:32:03.014374Z","shell.execute_reply":"2025-06-21T17:32:03.025658Z"},"_kg_hide-input":true},"outputs":[{"name":"stdout","text":"/kaggle/input/home-data-for-ml-course/sample_submission.csv\n/kaggle/input/home-data-for-ml-course/sample_submission.csv.gz\n/kaggle/input/home-data-for-ml-course/train.csv.gz\n/kaggle/input/home-data-for-ml-course/data_description.txt\n/kaggle/input/home-data-for-ml-course/test.csv.gz\n/kaggle/input/home-data-for-ml-course/train.csv\n/kaggle/input/home-data-for-ml-course/test.csv\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# **Import Libraries**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform, randint","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T17:32:05.235484Z","iopub.execute_input":"2025-06-21T17:32:05.235821Z","iopub.status.idle":"2025-06-21T17:32:10.071316Z","shell.execute_reply.started":"2025-06-21T17:32:05.235796Z","shell.execute_reply":"2025-06-21T17:32:10.070527Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# **Data Preparation**","metadata":{}},{"cell_type":"code","source":"# Load training and test data\ntrain_df = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/test.csv\")\n\n# Adds new derived features to the housing data\ndef add_features(df):\n    df = df.copy()\n    \n    # Total square footage\n    df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n    \n    # Total bathrooms\n    df['TotalBaths'] = (df['FullBath'] + 0.5 * df['HalfBath'] + df['BsmtFullBath'] + 0.5 * df['BsmtHalfBath'])\n    \n    # Age of house\n    df['HouseAge'] = df['YrSold'] - df['YearBuilt']\n    \n    # Years since remodel\n    df['YearsSinceRemodel'] = df['YrSold'] - df['YearRemodAdd']\n    \n    # Total porch area\n    df['TotalPorchSF'] = (df['OpenPorchSF'] + df['EnclosedPorch'] + df['3SsnPorch'] + df['ScreenPorch'])\n    \n    # Has pool (binary feature)\n    df['HasPool'] = (df['PoolArea'] > 0).astype(int)\n    \n    # Has garage (binary feature)\n    df['HasGarage'] = (df['GarageArea'] > 0).astype(int)\n    \n    # Has basement (binary feature)\n    df['HasBsmt'] = (df['TotalBsmtSF'] > 0).astype(int)\n    \n    # Has fireplace (binary feature)\n    df['HasFireplace'] = (df['Fireplaces'] > 0).astype(int)\n    \n    # Overall quality * overall condition interaction\n    df['OverallGrade'] = df['OverallQual'] * df['OverallCond']\n\n    # 3 neigborhoods with highest mean saleprice\n    df['ExpensiveArea'] = df['Neighborhood'].isin([\"NoRidge\", \"StoneBr\", \"NridgHt\"]).astype(int) \n\n    # Total number of \"conditions\" (features close to the house that may cause disturbances)\n    df['TotalCond'] = (df['Condition1'] != \"Norm\").astype(int) + (df['Condition2'] != \"Norm\").astype(int)\n \n    return df\n\n# Apply feature engineering to both datasets\ntrain_df_enhanced = add_features(train_df)\ntest_df_enhanced = add_features(test_df)\n\n# Split into training and validation sets\nX_train, X_test, y_train, y_test = train_test_split(\n    train_df_enhanced.drop('SalePrice', axis=1),\n    train_df_enhanced['SalePrice'],\n    test_size=0.2,\n    random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:58:38.294453Z","iopub.execute_input":"2025-06-21T20:58:38.294954Z","iopub.status.idle":"2025-06-21T21:06:47.831405Z","shell.execute_reply.started":"2025-06-21T20:58:38.294924Z","shell.execute_reply":"2025-06-21T21:06:47.830577Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Preprocessing Pipeline & Model Pipeline Creation**","metadata":{}},{"cell_type":"code","source":"# Identify feature types\ncategorical_cols = [cname for cname in X_train.columns\n                    if X_train[cname].dtype == \"object\" \n                    and cname != 'Id']  \n\nnumerical_cols = [cname for cname in X_train.columns\n                  if X_train[cname].dtype in ['int64', 'float64']\n                  and cname != 'Id']  \n\ncols = categorical_cols + numerical_cols\n\nprint(f\"Selected {len(categorical_cols)} categorical features: {categorical_cols[:5]}...\")\nprint(f\"Selected {len(numerical_cols)} numerical features: {numerical_cols[:5]}...\")\nprint(f\"Total features: {len(cols)}\")\n\n# Create processed datasets\ntrain = X_train[cols].copy()\nvalid = X_test[cols].copy()\ntest = test_df_enhanced[cols].copy() \n\n# Numerical data pipeline\nnumerical_transformer = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\n# Categorical data pipeline\ncategorical_transformer = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Combined preprocessing\npreprocessor = ColumnTransformer([\n    ('num', numerical_transformer, numerical_cols),\n    ('cat', categorical_transformer, categorical_cols)\n])\n\n# Model pipeline\nmodel = XGBRegressor(random_state=42)\npipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('model', model)\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:58:38.294453Z","iopub.execute_input":"2025-06-21T20:58:38.294954Z","iopub.status.idle":"2025-06-21T21:06:47.831405Z","shell.execute_reply.started":"2025-06-21T20:58:38.294924Z","shell.execute_reply":"2025-06-21T21:06:47.830577Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Hyperparameter Tuning**","metadata":{}},{"cell_type":"code","source":"# Hyperparameter tuning\nparam_dist = {\n    'model__n_estimators': randint(100, 1000),\n    'model__learning_rate': uniform(0.01, 0.19),\n    'model__max_depth': randint(3, 9),\n    'model__reg_alpha': uniform(0, 10),\n    'model__reg_lambda': uniform(1, 100),\n    'model__subsample': uniform(0.7, 0.3),\n    'model__colsample_bytree': uniform(0.7, 0.3),\n}\n\nrandom_search = RandomizedSearchCV(\n    pipeline,\n    param_distributions=param_dist,\n    n_iter=100,\n    cv=5,\n    scoring='neg_mean_absolute_error',\n    n_jobs=-1,\n    verbose=1,\n    random_state=42,\n    error_score='raise'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:58:38.294453Z","iopub.execute_input":"2025-06-21T20:58:38.294954Z","iopub.status.idle":"2025-06-21T21:06:47.831405Z","shell.execute_reply.started":"2025-06-21T20:58:38.294924Z","shell.execute_reply":"2025-06-21T21:06:47.830577Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model Training & Validation**","metadata":{}},{"cell_type":"code","source":"# Model training\nrandom_search.fit(train, y_train)\nbest_model = random_search.best_estimator_\n\n# Model validation\nval_predictions = best_model.predict(valid)\nval_mae = mean_absolute_error(y_test, val_predictions)\nprint(\"Validation MAE:\", val_mae)\n\n# Convert predictions into format that can be submitted to compettition \ntest_predictions = best_model.predict(test)\noutput = pd.DataFrame({'Id': test_df[\"Id\"], 'SalePrice': test_predictions})\noutput.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T20:58:38.294453Z","iopub.execute_input":"2025-06-21T20:58:38.294954Z","iopub.status.idle":"2025-06-21T21:06:47.831405Z","shell.execute_reply.started":"2025-06-21T20:58:38.294924Z","shell.execute_reply":"2025-06-21T21:06:47.830577Z"}},"outputs":[{"name":"stdout","text":"Selected 43 categorical features: ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour']...\nSelected 48 numerical features: ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond']...\nTotal features: 91\nFitting 5 folds for each of 100 candidates, totalling 500 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n  return op(a, b)\n","output_type":"stream"},{"name":"stdout","text":"Validation MAE: 14941.83344927226\n","output_type":"stream"}],"execution_count":null}]}