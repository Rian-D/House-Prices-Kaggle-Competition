{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10211,"databundleVersionId":111096,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T19:57:59.918633Z","iopub.execute_input":"2025-07-01T19:57:59.919096Z","iopub.status.idle":"2025-07-01T19:57:59.938595Z","shell.execute_reply.started":"2025-07-01T19:57:59.919060Z","shell.execute_reply":"2025-07-01T19:57:59.937375Z"},"_kg_hide-input":true},"outputs":[{"name":"stdout","text":"/kaggle/input/home-data-for-ml-course/sample_submission.csv\n/kaggle/input/home-data-for-ml-course/sample_submission.csv.gz\n/kaggle/input/home-data-for-ml-course/train.csv.gz\n/kaggle/input/home-data-for-ml-course/data_description.txt\n/kaggle/input/home-data-for-ml-course/test.csv.gz\n/kaggle/input/home-data-for-ml-course/train.csv\n/kaggle/input/home-data-for-ml-course/test.csv\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"# **Import Libraries**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform, randint","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T19:57:59.940577Z","iopub.execute_input":"2025-07-01T19:57:59.940884Z","iopub.status.idle":"2025-07-01T19:57:59.947178Z","shell.execute_reply.started":"2025-07-01T19:57:59.940854Z","shell.execute_reply":"2025-07-01T19:57:59.945960Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"# **Data Preparation**","metadata":{}},{"cell_type":"code","source":"# Load training and test data\ntrain_df = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/test.csv\")\nprint(f\"Training data shape: {train_df.shape}\")\nprint(f\"Test data shape: {test_df.shape}\\n\")\n\n# Adds new derived features to the housing data\ndef add_features(df):\n    df = df.copy()\n    \n    # Total square footage\n    df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n    \n    # Total bathrooms\n    df['TotalBaths'] = (df['FullBath'] + 0.5 * df['HalfBath'] + df['BsmtFullBath'] + 0.5 * df['BsmtHalfBath'])\n    \n    # Age of house\n    df['HouseAge'] = df['YrSold'] - df['YearBuilt']\n    \n    # Years since remodel\n    df['YearsSinceRemodel'] = df['YrSold'] - df['YearRemodAdd']\n    \n    # Total porch area\n    df['TotalPorchSF'] = (df['OpenPorchSF'] + df['EnclosedPorch'] + df['3SsnPorch'] + df['ScreenPorch'])\n    \n    # Has pool (binary feature)\n    df['HasPool'] = (df['PoolArea'] > 0).astype(int)\n    \n    # Has garage (binary feature)\n    df['HasGarage'] = (df['GarageArea'] > 0).astype(int)\n    \n    # Has basement (binary feature)\n    df['HasBsmt'] = (df['TotalBsmtSF'] > 0).astype(int)\n    \n    # Has fireplace (binary feature)\n    df['HasFireplace'] = (df['Fireplaces'] > 0).astype(int)\n    \n    # Overall quality * overall condition interaction\n    df['OverallGrade'] = df['OverallQual'] * df['OverallCond']\n\n    # 3 neigborhoods with highest mean saleprice\n    df['ExpensiveArea'] = df['Neighborhood'].isin([\"NoRidge\", \"StoneBr\", \"NridgHt\"]).astype(int) \n\n    # Total number of \"conditions\" (features close to the house that may cause disturbances)\n    df['TotalCond'] = (df['Condition1'] != \"Norm\").astype(int) + (df['Condition2'] != \"Norm\").astype(int)\n\n    # Average area per room\n    df[\"Spaciousness\"] = (df[\"1stFlrSF\"] + df[\"2ndFlrSF\"]) / df.TotRmsAbvGrd\n    \n    return df\n\n# Apply feature engineering to both datasets\ntrain_df_enhanced = add_features(train_df)\ntest_df_enhanced = add_features(test_df)\n\n# Split into training and validation sets\nX_train, X_test, y_train, y_test = train_test_split(\n    train_df_enhanced.drop('SalePrice', axis=1),\n    train_df_enhanced['SalePrice'],\n    test_size=0.2,\n    random_state=42\n)\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T19:57:59.948328Z","iopub.execute_input":"2025-07-01T19:57:59.948628Z","iopub.status.idle":"2025-07-01T19:58:00.043163Z","shell.execute_reply.started":"2025-07-01T19:57:59.948603Z","shell.execute_reply":"2025-07-01T19:58:00.042064Z"}},"outputs":[{"name":"stdout","text":"Training data shape: (1460, 81)\nTest data shape: (1459, 80)\n\nX_train shape: (1168, 94)\nX_test shape: (292, 94)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n  return op(a, b)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"# **Preprocessing Pipeline & Model Pipeline Creation**","metadata":{}},{"cell_type":"code","source":"# Identify feature types\ncategorical_cols = [cname for cname in X_train.columns\n                    if X_train[cname].dtype == \"object\" \n                    and cname != 'Id']  \n\nnumerical_cols = [cname for cname in X_train.columns\n                  if X_train[cname].dtype in ['int64', 'float64']\n                  and cname != 'Id']  \n\ncols = categorical_cols + numerical_cols\n\nprint(f\"Selected {len(categorical_cols)} categorical features: {categorical_cols[:5]}...\")\nprint(f\"Selected {len(numerical_cols)} numerical features: {numerical_cols[:5]}...\")\nprint(f\"Total features: {len(cols)}\")\n\n# Create processed datasets\ntrain = X_train[cols].copy()\nvalid = X_test[cols].copy()\ntest = test_df_enhanced[cols].copy() \n\n# Numerical data pipeline\nnumerical_transformer = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\n# Categorical data pipeline\ncategorical_transformer = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Combined preprocessing\npreprocessor = ColumnTransformer([\n    ('num', numerical_transformer, numerical_cols),\n    ('cat', categorical_transformer, categorical_cols)\n])\nprint(\"Preprocessing pipeline created\\n\")\n\n# Model pipeline\nmodel = XGBRegressor(random_state=42)\npipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('model', model)\n])\nprint(\"XGBoost model pipeline ready\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T19:58:00.044446Z","iopub.execute_input":"2025-07-01T19:58:00.044717Z","iopub.status.idle":"2025-07-01T19:58:00.066624Z","shell.execute_reply.started":"2025-07-01T19:58:00.044696Z","shell.execute_reply":"2025-07-01T19:58:00.065795Z"}},"outputs":[{"name":"stdout","text":"Selected 43 categorical features: ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour']...\nSelected 50 numerical features: ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond']...\nTotal features: 93\nPreprocessing pipeline created\n\nXGBoost model pipeline ready\n\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"# **Hyperparameter Tuning**","metadata":{}},{"cell_type":"code","source":"# Hyperparameter tuning\nparam_dist = {\n    'model__n_estimators': randint(100, 1000),\n    'model__learning_rate': uniform(0.01, 0.19),\n    'model__max_depth': randint(3, 9),\n    'model__reg_alpha': uniform(0, 10),\n    'model__reg_lambda': uniform(1, 100),\n    'model__subsample': uniform(0.7, 0.3),\n    'model__colsample_bytree': uniform(0.7, 0.3),\n}\n\nrandom_search = RandomizedSearchCV(\n    pipeline,\n    param_distributions=param_dist,\n    n_iter=100,\n    cv=5,\n    scoring='neg_mean_absolute_error',\n    n_jobs=-1,\n    verbose=1,\n    random_state=42,\n    error_score='raise'\n)\nprint(\"Randomized search configured with 100 iterations\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T19:58:00.068116Z","iopub.execute_input":"2025-07-01T19:58:00.068359Z","iopub.status.idle":"2025-07-01T19:58:00.080171Z","shell.execute_reply.started":"2025-07-01T19:58:00.068340Z","shell.execute_reply":"2025-07-01T19:58:00.079124Z"}},"outputs":[{"name":"stdout","text":"Randomized search configured with 100 iterations\n\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"# **Model Training & Validation**","metadata":{}},{"cell_type":"code","source":"# Model training\nrandom_search.fit(train, y_train)\nbest_model = random_search.best_estimator_\nprint(\"\\nTraining complete!\")\nprint(f\"Best parameters: {random_search.best_params_}\\n\")\n\n# Model validation\nval_predictions = best_model.predict(valid)\nval_mae = mean_absolute_error(y_test, val_predictions)\nprint(\"Validation MAE:\", val_mae)\n\n# Convert predictions into format that can be submitted to compettition \ntest_predictions = best_model.predict(test)\noutput = pd.DataFrame({'Id': test_df[\"Id\"], 'SalePrice': test_predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Submission file 'submission.csv' created successfully!\")\nprint(f\"Predicted price range: ${output['SalePrice'].min():,.0f} to ${output['SalePrice'].max():,.0f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T19:58:00.081319Z","iopub.execute_input":"2025-07-01T19:58:00.081564Z","iopub.status.idle":"2025-07-01T20:06:26.071161Z","shell.execute_reply.started":"2025-07-01T19:58:00.081544Z","shell.execute_reply":"2025-07-01T20:06:26.070141Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 100 candidates, totalling 500 fits\n\nTraining complete!\nBest parameters: {'model__colsample_bytree': 0.7885871765256816, 'model__learning_rate': 0.0712846452053341, 'model__max_depth': 3, 'model__n_estimators': 492, 'model__reg_alpha': 7.024840839871093, 'model__reg_lambda': 36.94911512197552, 'model__subsample': 0.7880775532793479}\n\nValidation MAE: 15521.614645761987\nSubmission file 'submission.csv' created successfully!\nPredicted price range: $57,624 to $512,966\n","output_type":"stream"}],"execution_count":36}]}